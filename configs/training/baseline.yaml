# =============================================================================
# Baseline Training Configuration
# =============================================================================

# Optimization
learning_rate: 4e-4
weight_decay: 0.05
warmup_steps: 1000
max_steps: 100000
grad_clip: 2.0
grad_accumulation_steps: 4  # Effective batch = 32 * 4 = 128

# Batch
batch_size: 32
num_workers: 4

# EMA
ema_decay: 0.9999
ema_warmup_steps: 1000

# Drifting Loss
drifting:
  temperatures: [0.02, 0.05, 0.2]
  normalize_features: true
  normalize_drift: true
  n_pos_samples: 64
  n_neg_samples: 64

# Mixed Precision
use_amp: true
amp_dtype: 'bfloat16'

# Distributed
use_fsdp: true
fsdp_shard_size: 100000000

# Checkpointing
checkpoint_dir: './checkpoints'
save_every_n_steps: 5000
keep_last_n_checkpoints: 5

# Logging
log_every_n_steps: 100
eval_every_n_steps: 1000

# WandB
wandb:
  project: 'drifting-vla'
  entity: null
  mode: 'online'
  tags: ['baseline']
  log_images: true
  log_videos: true
  theme: 'light'

  # Visualization frequencies (steps)
  visualizations:
    drifting_field:       { enabled: true, frequency: 500, num_samples: 100 }
    drift_trend:          { frequency: 200 }
    prediction_scatter:   { frequency: 500 }
    error_radar:          { frequency: 500 }
    temperature_loss:     { frequency: 500 }
    action_distribution:  { enabled: true, frequency: 500 }
    error_heatmap:        { frequency: 500 }
    trajectory_3d:        { enabled: true, frequency: 1000 }
    sample_transport:     { frequency: 500 }
    mode_coverage:        { frequency: 2000 }

# Simulation Evaluation (requires RLBench Docker image)
simulation_eval:
  enabled: true
  num_episodes: 3
  max_steps: 100
  tasks: ['close_jar']
  record_video: true
  video_fps: 10
  eval_freq: 5000
  use_dummy_env: false
